{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "pymongo                   3.4.0                    py36_0    defaults\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --quiet pymongo\n",
    "\n",
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to run Mongo from command line sshUbuntu@IP\n",
    "client = MongoClient('52.38.12.228', 27016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['52.38.12.228:27016'], document_class=dict, tz_aware=False, connect=True), 'projec4_database')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dbs\n",
    "client.projec4_database\n",
    "\n",
    "db_ref = client.project4_database\n",
    "# confirm dbs\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine_learning_collection', 'business_software_collections']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create collections\n",
    "ML_coll_ref = db_ref.machine_learning_collection\n",
    "BS_coll_ref = db_ref.business_software_collections\n",
    "#confirmn collections\n",
    "db_ref.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import article retrieval and cleaning libraries\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make requests and store to dictionary based on whether its page or category\n",
    "def category_pages(category):\n",
    "    pages_dict={}\n",
    "    subcat_dict={}\n",
    "    r = requests.get('http://en.wikipedia.org/w/api.php?action=query&\\\n",
    "                list=categorymembers&cmtitle=Category:{}&format=json&cmlimit=max'.format(category))\n",
    "    \n",
    "    ml_category_ls = r.json()['query']['categorymembers']\n",
    "    \n",
    "    # call pages_v_subcat function\n",
    "    pages,subcategories = pages_v_subcat(pages_dict,subcat_dict,ml_category_ls)\n",
    "    \n",
    "    return pages, subcategories\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if returned page is category or subcategory\n",
    "def pages_v_subcat(page_dict,subcat_dict,ml_ls):\n",
    "    for dictionary in ml_ls:\n",
    "        # ns !=14 indicates a page\n",
    "        if dictionary['ns'] != 14:\n",
    "            page_dict[dictionary['title']] = dictionary['pageid']\n",
    "        # ns ==14 indicates category\n",
    "        elif dictionary['ns'] == 14:\n",
    "            subcat_dict[dictionary['title']] = dictionary['pageid']\n",
    "            \n",
    "    return page_dict,subcat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all page_ids for specified number of layers\n",
    "def collect_page_ids(category,layers=3):\n",
    "    layers = layers\n",
    "    pages,subcats = category_pages(category)\n",
    "    while layers > 0:\n",
    "        try:\n",
    "            pages_next_layer = {}\n",
    "            subcat_next_layer = {}\n",
    "\n",
    "            for key in subcats.keys():\n",
    "                p,s = category_pages(key[9:])\n",
    "\n",
    "                pages_next_layer[key[9:]] = p\n",
    "\n",
    "                subcat_next_layer.update(s)\n",
    "\n",
    "            subcats = subcat_next_layer\n",
    "\n",
    "            for page in pages_next_layer.values():\n",
    "                for key,page2 in page.items():\n",
    "                    pages[key]=page2\n",
    "        except:\n",
    "            pass\n",
    "        layers -=1\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes noise from article text\n",
    "def clean_output(string):\n",
    "    clean_string = re.sub('<[^<]+?>', '',string)\n",
    "    clean_string2 = re.sub('\\n','',clean_string)\n",
    "    clean_string3 = re.sub(\"'\",'',clean_string2)\n",
    "#     clean_ls = element for element in clean_string.split('\\n') if element !=''\n",
    "    return clean_string3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_text_to_list (page_dictionary, master_list):\n",
    "    \n",
    "    for page_title,page_id in page_dictionary.items():\n",
    "        \n",
    "        page_results ={}\n",
    "        \n",
    "        page_request = requests.get('http://en.wikipedia.org/w/api.php?\\\n",
    "        action=query&prop=extracts&format=json&pageids={}'.format(page_id)) \n",
    "        \n",
    "        page_text = page_request.json()['query']['pages']['{}'.format(page_id)]['extract']\n",
    "        \n",
    "        clean_page_text = clean_output(page_text)\n",
    "        \n",
    "        page_results = {'page_title':page_title,\n",
    "                       'page_id':page_id,\n",
    "                       'page_text':clean_page_text}\n",
    "        \n",
    "        master_list.append(page_results)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all article text and stores to Mongo Collections\n",
    "def article_text_to_mongo (page_dictionary, mongo_collection):\n",
    "    \n",
    "    for page_title,page_id in page_dictionary.items():\n",
    "        try:\n",
    "            page_results ={}\n",
    "\n",
    "            page_request = requests.get('http://en.wikipedia.org/w/api.php?\\\n",
    "            action=query&prop=extracts&format=json&pageids={}'.format(page_id)) \n",
    "\n",
    "            page_text = page_request.json()['query']['pages']['{}'.format(page_id)]['extract']\n",
    "\n",
    "            clean_page_text = clean_output(page_text)\n",
    "\n",
    "            page_results = {'page_title':page_title,\n",
    "                           'page_id':page_id,\n",
    "                           'page_text':clean_page_text}\n",
    "\n",
    "\n",
    "            mongo_collection.insert_one(page_results)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # delays next request\n",
    "        time.sleep(np.random.randint(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = collect_page_ids('Machine learning',layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1117"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine learning page count\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_text_to_mongo(pages,ML_coll_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_coll_ref.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect business sofrtware pages\n",
    "bs_pages = collect_page_ids('Business software',layers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8147"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Business software page count\n",
    "len(bs_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text_to_mongo(bs_pages,BS_coll_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8146"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS_coll_ref.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
