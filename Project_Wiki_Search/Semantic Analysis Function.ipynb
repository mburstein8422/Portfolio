{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mongo imports\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "# Semantic Analysis imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mongo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates Mongo cursor of all data\n",
    "def mongo_cursor(collection_name,db_name='project4_database',IP='52.38.12.228',port=27016):\n",
    "    client = MongoClient(IP, port)\n",
    "    db_ref = client[db_name]\n",
    "    coll_ref = db_ref[collection_name]\n",
    "    \n",
    "    #query to return all records\n",
    "    cursor = coll_ref.find({})\n",
    "    \n",
    "    return cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts Mongo data to dictionary stored locally\n",
    "def extract_mongo_data(cursor,key_field='page_title',value_field='page_text' ):\n",
    "    data_dict = {}\n",
    "    \n",
    "    # only include required fields in dictionary\n",
    "    for obj in cursor:\n",
    "        data_dict[obj[key_field]] = obj[value_field]\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_collection_name = 'machine_learning_collection'\n",
    "BS_collection_name = 'business_software_collections'\n",
    "\n",
    "# tune text_vectorizer.  Used n_gram 2,2 to maintain more context\n",
    "text_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english',ngram_range=(2,2))\n",
    "# set at 120 because thats all my comp memory could handle, but during testing results improved higher this went\n",
    "SVD = TruncatedSVD(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_matrix(data,text_vectorizer=text_vectorizer,SVD=SVD):\n",
    "    \n",
    "    doc_matrix = text_vectorizer.fit_transform(data)\n",
    "    \n",
    "    # perform SVD/PCA to reduce the columns/features\n",
    "    svd_matrix = SVD.fit_transform(doc_matrix)\n",
    "    \n",
    "    return svd_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_search_results(search_terms,text_vectorizer=text_vectorizer,SVD=SVD):\n",
    "    \n",
    "    search_dict = {'search':search_terms}\n",
    "    \n",
    "    # only need to transform data to ensure shape is the same\n",
    "    search_matrix = text_vectorizer.transform(search_dict.values())\n",
    "    \n",
    "    search_svd = SVD.transform(search_matrix)\n",
    "    \n",
    "    return search_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(collection_name, search_terms):\n",
    "    \n",
    "    \n",
    "    # call extract_mongo & mongo_cursor\n",
    "    data_dict = extract_mongo_data(mongo_cursor(collection_name))\n",
    "    \n",
    "    data = data_dict.values()\n",
    "    \n",
    "    #call build document matric\n",
    "    svd_matrix = build_doc_matrix(data)\n",
    "    \n",
    "    # call transform search results\n",
    "    search_svd = transform_search_results(search_terms)\n",
    "    \n",
    "    return svd_matrix,search_svd,data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_articles(search_terms,collection_name,number_of_results=5):\n",
    "    \n",
    "    svd_matrix,search_svd,data_dict = prep_data(collection_name,search_terms)\n",
    "    \n",
    "    df_index = [num for num in range(len(data_dict))]\n",
    "    \n",
    "    results_df = pd.DataFrame(index=df_index)\n",
    "    \n",
    "    results_df['page'] = data_dict.keys()\n",
    "    \n",
    "    results_df['similiarity'] = cosine_similarity(svd_matrix,search_svd)\n",
    "    \n",
    "    return results_df.sort_values('similiarity',ascending=False).head(number_of_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>similiarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning</td>\n",
       "      <td>0.766729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adversarial machine learning</td>\n",
       "      <td>0.701522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Outline of machine learning</td>\n",
       "      <td>0.627945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Apache SystemML</td>\n",
       "      <td>0.573717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Michael I. Jordan</td>\n",
       "      <td>0.570788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             page  similiarity\n",
       "2                Machine learning     0.766729\n",
       "7    Adversarial machine learning     0.701522\n",
       "3     Outline of machine learning     0.627945\n",
       "478               Apache SystemML     0.573717\n",
       "813             Michael I. Jordan     0.570788"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine learning colleciton test\n",
    "search_articles('machine learning',ML_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business software colleciton test\n",
    "search_articles('QuickBooks',BS_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
